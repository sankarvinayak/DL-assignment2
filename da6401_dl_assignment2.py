# -*- coding: utf-8 -*-
"""DA6401_DL_assignment2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1242oRoCI9uVst-q3BimHxculawks1deC

# Problem Statement

In Part A and Part B of this assignment you will build and experiment with CNN based image classifiers using a subset of the [iNaturalist dataset](https://storage.googleapis.com/wandb_datasets/nature_12K.zip).

### Download the data and extract to the current directory
"""

!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip
!unzip -q nature_12K.zip
!pip install lightning

import os, random,torch,torchvision
import torch.nn as nn
import torch.functional as F
import torch.optim as optim
import pytorch_lightning as pl
from torchvision import transforms, datasets
from PIL import Image
from torch.utils.data import DataLoader, random_split
from torchvision import models
from pytorch_lightning.loggers import WandbLogger
from torchvision.datasets import ImageFolder
from torch.utils.data import Subset
from torch.nn import init

"""# Part A: Training from scratch

## Question 1 (5 Marks)
Build a small CNN model consisting of $5$ convolution layers. Each convolution layer would be followed by an activation and a max-pooling layer.

After $5$ such conv-activation-maxpool blocks, you should have one dense layer followed by the output layer containing $10$ neurons ($1$ for each of the $10$ classes). The input layer should be compatible with the images in the [iNaturalist dataset](https://storage.googleapis.com/wandb_datasets/nature_12K.zip) dataset.

The code should be flexible such that the number of filters, size of filters, and activation function of the convolution layers and dense layers can be changed. You should also be able to change the number of neurons in the dense layer.

- What is the total number of computations done by your network? (assume $m$ filters in each layer of size $k\times k$  and $n$ neurons in the dense layer)
- What is the total number of parameters in your network? (assume $m$ filters in each layer of size $k\times k$ and $n$ neurons in the dense layer)

### Create dataloader from the dataset
"""

class TransformedSubset(torch.utils.data.Dataset):
    def __init__(self, subset, transform):
        self.subset = subset
        self.transform = transform

    def __getitem__(self, index):
        x, y = self.subset[index]
        x = self.transform(x)
        return x, y

    def __len__(self):
        return len(self.subset)

class iNaturalistDataModule(pl.LightningDataModule):
    def __init__(self, train_dir: str,test_dir: str, batch_size: int=128, num_workers: int = 2,train_transforms=transforms.ToTensor(), test_transforms=transforms.ToTensor(), train_val_split: float = 0.8,seed=3407):
      super().__init__()

      self.save_hyperparameters()
      self.train_dir = train_dir
      self.test_dir = test_dir
      self.batch_size = batch_size
      self.num_workers = num_workers
      self.train_val_split = train_val_split

      self.train_transforms = train_transforms
      self.test_transforms=test_transforms
      self.seed=seed

    def setup(self, stage=None):
      torch.manual_seed(self.seed)
      torch.cuda.manual_seed(self.seed)
      full_dataset = ImageFolder(root=self.train_dir)
      total_size = len(full_dataset)
      train_size = int(total_size * self.train_val_split)
      val_size = total_size - train_size
      train_subset, val_subset = random_split(full_dataset, [train_size, val_size])
      self.train_dataset = TransformedSubset(train_subset, self.train_transforms)
      self.val_dataset = TransformedSubset(val_subset, self.test_transforms)
      self.test_dataset = ImageFolder(root=self.test_dir, transform=self.test_transforms)

    def train_dataloader(self):
      return DataLoader(self.train_dataset,batch_size=self.batch_size,shuffle=True,num_workers=self.num_workers)

    def val_dataloader(self):

      return DataLoader(self.val_dataset,batch_size=self.batch_size,shuffle=False, num_workers=self.num_workers)

    def test_dataloader(self):
      return DataLoader(self.test_dataset,batch_size=self.batch_size,shuffle=False,num_workers=self.num_workers)

transform=transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor()])
naturalist_DM=iNaturalistDataModule(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',train_transforms=transform,test_transforms=transform)
naturalist_DM.setup()

train_loader=naturalist_DM.train_dataloader()
val_loader=naturalist_DM.val_dataloader()
test_loader=naturalist_DM.test_dataloader()

img = Image.open("inaturalist_12K/train/Amphibia/02f95591e712f05cae136a91a4d73ea5.jpg")
width, height = img.size
print(f"Width: {width}, Height: {height}")

import torch
mean = torch.zeros(3)
std = torch.zeros(3)
total_samples = 0
for images, _ in train_loader:
    batch_samples = images.size(0)
    images = images.view(batch_samples, 3, -1)

    mean += images.mean(dim=2).sum(dim=0)
    std += images.std(dim=2).sum(dim=0)
    total_samples += batch_samples

mean /= total_samples
std /= total_samples

print(f"Computed Mean: {mean.tolist()}")
print(f"Computed Std: {std.tolist()}")



train_loader = naturalist_DM.train_dataloader()
shape=None
for images, labels in train_loader:
    print("Batch image shape:", images.shape)
    shape=images.shape
    break
shape

class iNaturalistModel(pl.LightningModule):
    def __init__(self, in_channels=3,input_size=(224, 224),dense_size=512,  num_filters_layer: list = [16, 32, 64, 128, 256],filter_size: list = [3, 3, 3, 3, 3], stride=1,  padding=1, num_classes=10,activation=nn.ReLU,dropout_rate=0,optimizer=torch.optim.AdamW,lr=1e-3,batch_norm=False ):
        super().__init__()
        self.save_hyperparameters()
        self.optimizer=optimizer
        self.lr=lr
        layers = []
        size = input_size
        activation_name=activation.__name__.lower()
        for num_channel, k in zip(num_filters_layer, filter_size):
            conv=nn.Conv2d(in_channels=in_channels,out_channels=num_channel,kernel_size=k,stride=stride,padding=padding)
            layers.append(conv)
            if batch_norm:
              layers.append(nn.BatchNorm2d(num_features=num_channel))
            layers.append(activation())
            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))
            in_channels = num_channel
            conv_h = (size[0] + 2 * padding - k) // stride + 1
            conv_w = (size[1] + 2 * padding - k) // stride + 1
            pool_h = conv_h // 2
            pool_w = conv_w // 2
            size = (pool_h, pool_w)
        layers.append(nn.Flatten())
        if dropout_rate > 0:
            layers.append(nn.Dropout(dropout_rate))
        flattened_size = size[0] * size[1] * num_filters_layer[-1]
        fc1=nn.Linear(in_features=flattened_size, out_features=dense_size)

        layers.append(fc1)
        layers.append(activation())
        if dropout_rate > 0:
            layers.append(nn.Dropout(dropout_rate))
        fc2=nn.Linear(in_features=dense_size, out_features=num_classes)
        layers.append(fc2)
        self.model = nn.Sequential(*layers)
    def forward(self, x):
        return self.model(x)
    def training_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("train_acc", acc, prog_bar=True)
        self.log("train_loss", loss, prog_bar=True)
        return loss
    def validation_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("validation_acc", acc, prog_bar=True)
        self.log("validation_loss", loss, prog_bar=True)
        return {"validation_loss":loss,"validation_acc":acc}
    def test_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("test_acc", acc, prog_bar=True)
        self.log("test_loss", loss, prog_bar=True)
        return {"test_loss":loss,"test_acc":acc}
    def configure_optimizers(self):
        return self.optimizer(self.model.parameters(), lr=self.lr,weight_decay=1e-5)

"""## Question 2 (15 Marks)
You will now train your model using the [iNaturalist dataset](https://storage.googleapis.com/wandb_datasets/nature_12K.zip). The zip file contains a train and a test folder. Set aside $20\%$ of the training data, as validation data, for hyperparameter tuning. Make sure each class is equally represented in the validation data. **Do not use the test data for hyperparameter tuning.**

Using the sweep feature in wandb find the best hyperparameter configuration. Here are some suggestions but you are free to decide which hyperparameters you want to explore

- number of filters in each layer : $32$, $64$, ...
- activation function for the conv layers: ReLU, GELU, SiLU, Mish, ...
- filter organisation: same number of filters in all layers, doubling in each subsequent layer, halving in each subsequent layer, etc
- data augmentation: Yes, No
- batch normalisation: Yes, No
- dropout: $0.2$, $0.3$ (BTW, where will you add dropout? You should read up a bit on this)

Based on your sweep please paste the following plots which are automatically generated by wandb:
- accuracy v/s created plot (I would like to see the number of experiments you ran to get the best configuration).
- parallel co-ordinates plot
- correlation summary table (to see the correlation of each hyperparameter with the loss/accuracy)

Also, write down the hyperparameters and their values that you sweeped over. Smart strategies to reduce the number of runs while still achieving a high accuracy would be appreciated. Write down any unique strategy that you tried.

overfitting
"""

model=iNaturalistModel()
trainer=pl.Trainer(max_epochs=30)
trainer.fit(model,train_dataloaders=train_loader,val_dataloaders=val_loader)

"""too slow to improve"""

model=iNaturalistModel(num_filters_layer = [64,128,256,512,1024],filter_size = [7, 5, 5, 3, 3], stride=1,  padding=1, num_classes=10,activation=torch.nn.GELU,dropout_rate=0.5,optimizer=torch.optim.AdamW,lr=1e-3,batch_norm=True )
trainer=pl.Trainer(max_epochs=30)
trainer.fit(model,train_dataloaders=train_loader,val_dataloaders=val_loader)

model=iNaturalistModel(dense_size=4096,num_filters_layer = [32,64,128,256,512],filter_size = [5, 5, 3, 3, 3], stride=1,  padding=1, num_classes=10,activation=torch.nn.ReLU,dropout_rate=0.5,optimizer=torch.optim.AdamW,lr=1e-2,batch_norm=True )
trainer=pl.Trainer(max_epochs=30)
naturalist_DM=iNaturalistDataModule(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',train_transforms=transform,test_transforms=transform,batch_size=64)
naturalist_DM.setup()
trainer.fit(model,datamodule=naturalist_DM)

import torchvision.transforms as transforms

transform = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)], p=0.3),
    transforms.RandomRotation(degrees=15),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
naturalist_DM=iNaturalistDataModule(train_dir='/content/inaturalist_12K/train',test_dir='/content/inaturalist_12K/val',train_transforms=transform,test_transforms=transform)
naturalist_DM.setup()

model=iNaturalistModel(dense_size=4096,num_filters_layer = [32,64,128,256,512],filter_size = [3, 3, 3, 3, 3], stride=1,  padding=1, num_classes=10,activation=torch.nn.ReLU,dropout_rate=0.5,optimizer=torch.optim.Adam,lr=1e-4,batch_norm=True )
trainer=pl.Trainer(max_epochs=30)
trainer.fit(model,datamodule=naturalist_DM)

import torch.nn.init as init


class iNaturalistModel(pl.LightningModule):
    def __init__(self, in_channels=3,input_size=(224, 224),dense_size=512,  num_filters_layer: list = [16, 32, 64, 128, 256],filter_size: list = [3, 3, 3, 3, 3], stride=1,  padding=1, num_classes=10,activation=nn.ReLU,dropout_rate=0,optimizer=torch.optim.AdamW,lr=1e-3,batch_norm=False ):
        super().__init__()
        self.save_hyperparameters()
        self.optimizer=optimizer
        self.lr=lr
        layers = []
        size = input_size
        activation_name=activation.__name__.lower()
        for num_channel, k in zip(num_filters_layer, filter_size):
            conv=nn.Conv2d(in_channels=in_channels,out_channels=num_channel,kernel_size=k,stride=stride,padding=padding)
            if activation_name in ["relu", "mish"]:
                init.kaiming_normal_(conv.weight, nonlinearity='relu')
            elif activation_name in ["silu", "gelu"]:
                init.kaiming_normal_(conv.weight, nonlinearity="linear")
            else:
              init.xavier_normal_(conv.weight)
            if conv.bias is not None:
                init.zeros_(conv.bias)
            layers.append(conv)

            if batch_norm:
              layers.append(nn.BatchNorm2d(num_features=num_channel))
            layers.append(activation())
            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))
            in_channels = num_channel
            conv_h = (size[0] + 2 * padding - k) // stride + 1
            conv_w = (size[1] + 2 * padding - k) // stride + 1
            pool_h = conv_h // 2
            pool_w = conv_w // 2
            size = (pool_h, pool_w)
        layers.append(nn.Flatten())
        if dropout_rate > 0:
            layers.append(nn.Dropout(dropout_rate))
        flattened_size = size[0] * size[1] * num_filters_layer[-1]
        fc1=nn.Linear(in_features=flattened_size, out_features=dense_size)
        if activation_name=="relu":
          init.kaiming_normal_(fc1.weight, nonlinearity='relu')
        else:
          init.xavier_normal_(fc1.weight)
        if fc1.bias is not None:
            init.zeros_(fc1.bias)
        layers.append(fc1)
        layers.append(activation())
        if dropout_rate > 0:
            layers.append(nn.Dropout(dropout_rate))
        fc2=nn.Linear(in_features=dense_size, out_features=num_classes)
        init.xavier_normal_(fc2.weight)
        if fc2.bias is not None:
            init.zeros_(fc2.bias)
        layers.append(fc2)
        self.model = nn.Sequential(*layers)
    def forward(self, x):
        return self.model(x)
    def training_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("train_acc", acc, prog_bar=True)
        self.log("train_loss", loss, prog_bar=True)
        return loss
    def validation_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("validation_acc", acc, prog_bar=True)
        self.log("validation_loss", loss, prog_bar=True)
        return {"validation_loss":loss,"validation_acc":acc}
    def test_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("test_acc", acc, prog_bar=True)
        self.log("test_loss", loss, prog_bar=True)
        return {"test_loss":loss,"test_acc":acc}
    def configure_optimizers(self):
        return self.optimizer(self.model.parameters(), lr=self.lr,weight_decay=1e-5)











trainer.test(model,test_loader)

import wandb
sweep_config = {
    "method": "bayes",
    "metric": {
        "name": "validation_loss",
        "goal": "minimize"
    },
    "parameters": {
        "num_filter": {
            "values":[16,32,64]
        },
        "activation_fun": {
            "values":["ReLU", "GELU", "SiLU", "Mish"]
        },
        "filter_org": {
            "values":["same","double"]
        },
        "data_augmentation": {
            "values":["No","Yes"]
        },
        "batch_norm": {
            "values":["No","Yes"]
        },
        "dropout": {
            "values":[0,0.2,0.3,0.5,0.7]
        },

        "filter_size": {
            "values":[3,5,7]
        },
        "epoch": {
            "values":[5,10,20]
        },
        "batch_size": {
            "values":[32,64,128,256]
        },"dene_size": {
            "values":[512,1024,2046]
        },"lr": {
            "values":[1e-3,5e-4,1e-4]
        }
    }
}
sweep_id = wandb.sweep(sweep_config, project="DL-Addignemt2_A")

from pytorch_lightning.loggers import WandbLogger
def train_model():
    torch.manual_seed(3407)
    wandb.init()
    config = wandb.config
    run_name = f"Augment{config.data_augmentation}activation_fun{config.activation_fun}_dropout_{config.dropout}"
    wandb.run.name = run_name

    if config.data_augmentation == "Yes":
      train_transforms = transforms.Compose([
      transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
      transforms.RandomHorizontalFlip(p=0.5),
      transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)], p=0.3),
      transforms.RandomRotation(degrees=15),
      transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
      transforms.RandomPerspective(distortion_scale=0.2, p=0.3),
      transforms.ToTensor(),
      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
  ])
    else:
      train_transforms = transforms.Compose([
      transforms.Resize((224,224)),
      transforms.ToTensor(),
      transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),])
    num_filters=config.num_filter
    num_filters_layer=[num_filters,num_filters*2,num_filters*4,num_filters*8,num_filters*16]if config.filter_org=="double" else [num_filters]*5
    if config.activation_fun=="ReLU":
      activation=torch.nn.ReLU
    elif config.activation_fun=="GELU":
      activation=torch.nn.GELU
    elif config.activation_fun=="SiLU":
      activation=torch.nn.SiLU
    elif config.activation_fun=="Mish":
      activation=nn.Mish
    filter_size=config.filter_size
    filter_sizes=[filter_size]*5
    if config.batch_norm=="Yes":
      model = iNaturalistModel(num_filters_layer=num_filters_layer,activation=activation,dropout_rate=config.dropout,batch_norm=True,filter_size=filter_sizes,dense_size=config.dense_size,lr=config.lr)
    else:
      model = iNaturalistModel(num_filters_layer=num_filters_layer,activation=activation,dropout_rate=config.dropout,filter_size=filter_sizes,dense_size=config.dense_size,lr=config.lr)
    print(model)



    wandb_logger = WandbLogger(project="DL-Addignemt2_A",name=run_name)
    trainer = pl.Trainer(logger=wandb_logger, max_epochs=config.epoch)

    test_tranform=transforms.Compose([
            transforms.Resize((224,224)),
            transforms.ToTensor()])
    naturalist_DM=iNaturalistDataModule(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',batch_size=config.batch_size,train_transforms=train_transforms,test_transforms=test_tranform)
    trainer.fit(model, naturalist_DM)

import wandb
wandb.login()

import wandb
wandb.agent("cs24m041-iit-madras/DL-Addignemt2_A/hpejw85x", function=train_model)

import wandb

sweep_config = {
    "method": "bayes",
    "metric": {
        "name": "validation_loss",
        "goal": "minimize"
    },
    "parameters": {
        "num_filter": {
            "values": [16, 32, 64, 128]
        },
        "activation_fun": {
            "values": ["ReLU", "GELU", "SiLU", "Mish"]
        },
        "filter_org": {
            "values": ["same", "double", "half"]
        },
        "data_augmentation": {
            "values": ["No", "Yes"]
        },
        "batch_norm": {
            "values": ["No", "Yes"]
        },
        "dropout": {
            "values": [0, 0.2, 0.3, 0.5, 0.7]
        },
        "filter_size": {
            "values": [
                [3, 3, 3, 3, 3],
                [3, 3, 3, 5, 5],
                [5, 5, 7, 7, 7],
                [3, 5, 5, 7, 7],
                [7, 7, 5, 5, 3],
                [7, 5, 5, 3, 3],
                [5, 5, 7, 7, 7],
                [3, 5, 5, 7, 7],
                [3, 3, 5, 5, 7]
            ]
        },
        "epoch": {
            "values": [5, 10, 20]
        },
        "batch_size": {
            "values": [32, 64, 128]
        },
        "dense_size": {
            "values": [512, 1024, 2046]
        },
        "lr": {
            "values": [1e-3, 5e-4, 1e-4]
        }
    }
}

sweep_id = wandb.sweep(sweep_config, project="DL-Addignemt2_A")

from pytorch_lightning.callbacks import EarlyStopping
from pytorch_lightning.loggers import WandbLogger
def train_model():
    torch.manual_seed(3407)
    torch.cuda.manual_seed(3407)
    wandb.init()
    config = wandb.config
    run_name = f"Augment{config.data_augmentation}activation_fun{config.activation_fun}_dropout_{config.dropout}"
    wandb.run.name = run_name

    if config.data_augmentation == "Yes":
      train_transforms = transforms.Compose([
      transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
      transforms.RandomHorizontalFlip(p=0.5),
      transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)], p=0.3),
      transforms.RandomRotation(degrees=15),
      transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
      transforms.RandomPerspective(distortion_scale=0.2, p=0.3),
      transforms.ToTensor(),
      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
  ])
    else:
      train_transforms = transforms.Compose([
      transforms.Resize((224,224)),
      transforms.ToTensor(),
      transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),])
    num_filters=config.num_filter
    if config.filter_org=="double":
      num_filters_layer=[num_filters,num_filters*2,num_filters*4,num_filters*8,num_filters*16]
    elif config.filter_org=="half":
      num_filters_layer=[num_filters,num_filters//2,num_filters//4,num_filters//8,num_filters//16]
    else:
     num_filters_layer=[num_filters]*5
    if config.activation_fun=="ReLU":
      activation=torch.nn.ReLU
    elif config.activation_fun=="GELU":
      activation=torch.nn.GELU
    elif config.activation_fun=="SiLU":
      activation=torch.nn.SiLU
    elif config.activation_fun=="Mish":
      activation=nn.Mish
    filter_sizes=config.filter_size
    # filter_sizes=[filter_size]*5
    if config.batch_norm=="Yes":
      model = iNaturalistModel(num_filters_layer=num_filters_layer,activation=activation,dropout_rate=config.dropout,batch_norm=True,filter_size=filter_sizes,dense_size=config.dense_size,lr=config.lr)
    else:
      model = iNaturalistModel(num_filters_layer=num_filters_layer,activation=activation,dropout_rate=config.dropout,filter_size=filter_sizes,dense_size=config.dense_size,lr=config.lr)
    print(model)

    early_stop_cb = EarlyStopping(
    monitor="validation_loss",
    min_delta=0.00,
    patience=10,
    verbose=True,
    mode="min"
)

    wandb_logger = WandbLogger(project="DL-Addignemt2_A",name=run_name)
    trainer = pl.Trainer(logger=wandb_logger, max_epochs=config.epoch,callbacks=[early_stop_cb])
    test_tranform=transforms.Compose([
            transforms.Resize((224,224)),
            transforms.ToTensor()])
    naturalist_DM=iNaturalistDataModule(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',batch_size=config.batch_size,train_transforms=train_transforms,test_transforms=test_tranform)
    trainer.fit(model, naturalist_DM)

import wandb
wandb.agent("cs24m041-iit-madras/DL-Addignemt2_A/ufebm2l1", function=train_model)















wandb.agent(sweep_id, function=train_model, count=10)

import wandb
wandb.agent("cs24m041-iit-madras/DL-Addignemt2_A/46ppefcs", function=train_model)

"""recovered from history"""



class iNaturalistDataModule(pl.LightningDataModule):
    def __init__(self, train_dir: str,test_dir: str, batch_size: int=128, num_workers: int = 2,train_transforms=transforms.ToTensor(), test_transforms=transforms.ToTensor(), train_val_split: float = 0.8,seed=3407):
      super().__init__()

      self.save_hyperparameters()
      self.train_dir = train_dir
      self.test_dir = test_dir
      self.batch_size = batch_size
      self.num_workers = num_workers
      self.train_val_split = train_val_split

      self.train_transforms = train_transforms
      self.test_transforms=test_transforms
      self.seed=seed

    def setup(self, stage=None):
      torch.manual_seed(self.seed)
      torch.cuda.manual_seed(self.seed)
      train_dataset = datasets.ImageFolder(root=self.train_dir, transform=self.train_transforms)
      total_size = len(train_dataset)
      train_size = int(total_size * self.train_val_split)
      val_size = total_size - train_size
      self.train_dataset, self.val_dataset = random_split(train_dataset, [train_size, val_size])

      self.test_dataset = datasets.ImageFolder(root=self.test_dir, transform=self.test_transforms)

    def train_dataloader(self):
      return DataLoader(self.train_dataset,batch_size=self.batch_size,shuffle=True,num_workers=self.num_workers)

    def val_dataloader(self):

      return DataLoader(self.val_dataset,batch_size=self.batch_size,shuffle=False, num_workers=self.num_workers)

    def test_dataloader(self):
      return DataLoader(self.test_dataset,batch_size=self.batch_size,shuffle=False,num_workers=self.num_workers)

class iNaturalistModel(pl.LightningModule):
    def __init__(self, in_channels=3,input_size=(224, 224),dense_size=512,  num_filters_layer: list = [16, 32, 64, 128, 256],filter_size: list = [3, 3, 3, 3, 3], stride=1,  padding=1, num_classes=10,activation=nn.ReLU,dropout_rate=0,optimizer=torch.optim.Adam,lr=0.001,batch_norm=False ):
        super().__init__()
        self.save_hyperparameters()
        self.optimizer=optimizer
        self.lr=lr
        layers = []
        size = input_size
        for num_channel, k in zip(num_filters_layer, filter_size):
            if padding==1:
                padding=k//2
            layers.append(nn.Conv2d(in_channels=in_channels,out_channels=num_channel,kernel_size=k,stride=stride,padding=padding))
            if batch_norm:
              layers.append(nn.BatchNorm2d(num_features=num_channel))
            layers.append(activation())
            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))
            in_channels = num_channel
            conv_h = (size[0] + 2 * padding - k) // stride + 1
            conv_w = (size[1] + 2 * padding - k) // stride + 1
            pool_h = conv_h // 2
            pool_w = conv_w // 2
            size = (pool_h, pool_w)
        layers.append(nn.Flatten())
        if dropout_rate > 0:
            layers.append(nn.Dropout(dropout_rate))
        flattened_size = size[0] * size[1] * num_filters_layer[-1]
        layers.append(nn.Linear(in_features=flattened_size, out_features=dense_size))
        layers.append(activation())
        layers.append(nn.Linear(in_features=dense_size, out_features=num_classes))
        self.model = nn.Sequential(*layers)
    def forward(self, x):
        return self.model(x)
    def training_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("train_acc", acc, prog_bar=True)
        self.log("train_loss", loss, prog_bar=True)
        return loss
    def validation_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("validation_acc", acc, prog_bar=True)
        self.log("validation_loss", loss, prog_bar=True)
        return {"validation_loss":loss,"validation_acc":acc}
    def test_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("test_acc", acc, prog_bar=True)
        self.log("test_loss", loss, prog_bar=True)
        return {"test_loss":loss,"test_acc":acc}
    def configure_optimizers(self):
        return self.optimizer(self.model.parameters(), lr=self.lr)

train_transforms = transforms.Compose([
      transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
      transforms.RandomHorizontalFlip(p=0.5),
      transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)], p=0.3),
      transforms.RandomRotation(degrees=15),
      transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
      transforms.RandomPerspective(distortion_scale=0.2, p=0.3),
      transforms.ToTensor(),
      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])

test_transforms = transforms.Compose([
    transforms.Resize(256),            # shorter side → 256px
    transforms.CenterCrop(224),        # then 224×224 center patch
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

wandb.finish()

import pytorch_lightning as pl
from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint
from pytorch_lightning.loggers import WandbLogger
activation_fun="SiLU"
activation=torch.nn.SiLU
batch_norm="Yes"
batch_size=64
data_augmentation="Yes"
dense_size=1024
dropout=0.5
epoch=50
filter_org="double"
filter_size=3
filter_sizes=[filter_size]*5
lr=0.0001
num_filters=32


early_stop_cb = EarlyStopping(
    monitor="validation_loss",
    min_delta=0.00,
    patience=10,
    verbose=True,
    mode="min"
)
checkpoint_cb = ModelCheckpoint(
    monitor="validation_loss",
    mode="min",
    save_top_k=1,
    verbose=True,
    dirpath="checkpoints/",
    filename="best-model"
)


num_filters_layer=[num_filters,num_filters*2,num_filters*4,num_filters*8,num_filters*16]
# num_filters_layer=[num_filters]*5

run_name = f"Augment{data_augmentation}activation_fun{activation_fun}_dropout_{dropout}"
torch.manual_seed(3407)
wandb_logger = WandbLogger(project="DL-Addignemt2_A",name=run_name)

model = iNaturalistModel(num_filters_layer=num_filters_layer,activation=activation,dropout_rate=dropout,batch_norm=True,filter_size=filter_sizes,dense_size=dense_size,lr=lr)
naturalist_DM=iNaturalistDataModule(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',batch_size=batch_size,train_transforms=train_transforms,test_transforms=test_transforms)

trainer = pl.Trainer(logger=wandb_logger, max_epochs=epoch,callbacks=[early_stop_cb,checkpoint_cb])
trainer.fit(model, naturalist_DM)

best_model = iNaturalistModel.load_from_checkpoint(checkpoint_cb.best_model_path)

trainer.test(best_model, datamodule=naturalist_DM)

torch.save(model.state_dict(), "44%test.pth")





from torchvision.datasets import ImageFolder

from torchvision.datasets import ImageFolder

class ImageFolderWithPaths(ImageFolder):
    def __getitem__(self, index):
        original_tuple = super().__getitem__(index)
        path = self.imgs[index][0]
        return original_tuple + (path,)

class iNaturalistDataModule_new(pl.LightningDataModule):
    def __init__(self, train_dir: str,test_dir: str, batch_size: int=128, num_workers: int = 2,train_transforms=transforms.ToTensor(), test_transforms=transforms.ToTensor(), train_val_split: float = 0.8,seed=3407):
      super().__init__()

      self.save_hyperparameters()
      self.train_dir = train_dir
      self.test_dir = test_dir
      self.batch_size = batch_size
      self.num_workers = num_workers
      self.train_val_split = train_val_split

      self.train_transforms = train_transforms
      self.test_transforms=test_transforms
      self.seed=seed

    def setup(self, stage=None):
      torch.manual_seed(self.seed)
      torch.cuda.manual_seed(self.seed)

      train_dataset = ImageFolderWithPaths(root=self.train_dir, transform=self.train_transforms)
      total_size = len(train_dataset)
      train_size = int(total_size * self.train_val_split)
      val_size = total_size - train_size
      self.train_dataset, self.val_dataset = random_split(train_dataset, [train_size, val_size])

      self.test_dataset = ImageFolderWithPaths(root=self.test_dir, transform=self.test_transforms)

    def train_dataloader(self):
      return DataLoader(self.train_dataset,batch_size=self.batch_size,shuffle=True,num_workers=self.num_workers)

    def val_dataloader(self):

      return DataLoader(self.val_dataset,batch_size=self.batch_size,shuffle=False, num_workers=self.num_workers)

    def test_dataloader(self):
      return DataLoader(self.test_dataset,batch_size=self.batch_size,shuffle=False,num_workers=self.num_workers)
naturalist_DM_new = iNaturalistDataModule_new(
    train_dir='inaturalist_12K/train',
    test_dir='inaturalist_12K/val',
    batch_size=batch_size,
    train_transforms=train_transforms,
    test_transforms=test_transforms
)
naturalist_DM_new.setup()

class_names = naturalist_DM_new.test_dataset.classes
test_loader = naturalist_DM_new.test_dataloader()

show_prediction_grid(model, test_loader, class_names, device='cuda')

import torch
import random
import matplotlib.pyplot as plt
from PIL import Image

def show_random_predictions(model, dataset, class_names, device='cuda', num_samples=30, rows=3, cols=10):
    model.eval()
    indices = random.sample(range(len(dataset)), num_samples)
    samples = [dataset[i] for i in indices]

    fig, axes = plt.subplots(rows, cols, figsize=(20, 6))
    axes = axes.flatten()

    with torch.no_grad():
        for i, (img, label, path) in enumerate(samples):
            img_tensor = img.unsqueeze(0).to(device)  # add batch dim
            output = model(img_tensor)
            pred = output.argmax(dim=1).item()

            # Load image again to plot (optional)
            img_display = Image.open(path).convert("RGB")

            ax = axes[i]
            ax.imshow(img_display)
            ax.axis("off")
            ax.set_title(f"Pred: {class_names[pred]}\nActual: {class_names[label]}", fontsize=8)

    plt.tight_layout()
    plt.show()

show_random_predictions(model, naturalist_DM_new.test_dataset, class_names, device='cuda')

import random
import torch
from PIL import Image
import wandb

def log_random_predictions_separate(
    model,
    dataset,
    class_names,
    device='cuda',
    num_samples=30,
    key="random_preds"
):

    model.eval()
    # 2. Pick random samples
    indices = random.sample(range(len(dataset)), num_samples)
    samples = [dataset[i] for i in indices]

    # 3. Build list of wandb.Image
    images_to_log = []
    with torch.no_grad():
        for img_tensor, label, path in samples:
            # run model
            inp = img_tensor.unsqueeze(0).to(device)
            output = model(inp)
            pred = output.argmax(dim=1).item()

            # load for display
            img = Image.open(path).convert("RGB")
            caption = f"Pred: {class_names[pred]} / Actual: {class_names[label]}"
            images_to_log.append(wandb.Image(img, caption=caption))

    # 4. Log all images in one call
    wandb.log({ key: images_to_log })

wandb.init(project="DL-Addignemt2_A")
log_random_predictions_separate(
    model,
    naturalist_DM_new.test_dataset,      # must return (img_tensor, label, path) per __getitem__
    class_names,     # list of str
    device='cuda',
    num_samples=30,
    key="Model prediction"
)
wandb.finish()











"""## Question 3 (15 Marks)
Based on the above plots write down some insightful observations. For example,
- adding more filters in the initial layers is better
- Using bigger filters in initial layers and smaller filters in latter layers is better
- ... ...

(Note: I don't know if any of the above statements is true. I just wrote some random comments that came to my mind)

-
-
-
-
-
"""







"""
## Question 4 (5 Marks)
You will now apply your best model on the test data (You shouldn't have used test data so far. All the above experiments should have been done using train and validation data only).

- Use the best model from your sweep and report the accuracy on the test set.
- Provide a $10 \times 3$ grid containing sample images from the test data and predictions made by your best model (more marks for presenting this grid creatively).
- **(UNGRADED, OPTIONAL)** Visualise all the filters in the first layer of your best model for a random image from the test set. If there are 64 filters in the first layer plot them in an $8 \times 8$ grid.
- **(UNGRADED, OPTIONAL)** Apply guided back-propagation on any $10$ neurons in the CONV5 layer and plot the images which excite this neuron. The idea again is to discover interesting patterns which excite some neurons. You will draw a $10 \times 1$ grid below with one image for each of the $10$ neurons.
"""



"""

## Question 5 (10 Marks)
Paste a link to your github code for Part A

Example: https://github.com/&lt;user-id&gt;/da6401_assignment2/partA;

- We will check for coding style, clarity in using functions and a ```README``` file with clear instructions on training and evaluating the model (the 10 marks will be based on this).
- We will also run a plagiarism check to ensure that the code is not copied (0 marks in the assignment if we find that the code is plagiarised).
- We will also check if the training and test data has been split properly and randomly. You will get 0 marks on the assignment if we find any cheating (e.g., adding test data to training data) to get higher accuracy.
"""





"""# Part B : Fine-tuning a pre-trained model

## Question 1 (5 Marks)
In most DL applications, instead of training a model from scratch, you would use a model pre-trained on a similar/related task/dataset. From ```torchvision```, you can load **ANY ONE** [model](https://pytorch.org/vision/stable/models.html) (```GoogLeNet```, ```InceptionV3```, ```ResNet50```, ```VGG```, ```EfficientNetV2```, ```VisionTransformer``` etc.) pre-trained  on the ImageNet dataset. Given that ImageNet also contains many animal images, it stands to reason that using a model pre-trained on ImageNet maybe helpful for this task.

You will load a pre-trained model and then fine-tune it using the naturalist data that you used in the previous question. Simply put, instead of randomly initialising the weigths of a network you will use the weights resulting from training the model on the ImageNet data (```torchvision``` directly provides these weights). Please answer the following questions:

- The dimensions of the images in your data may not be the same as that in the ImageNet data. How will you address this?
- ImageNet has $1000$ classes and hence the last layer of the pre-trained model would have $1000$ nodes. However, the naturalist dataset has only $10$ classes. How will you address this?

(Note: This question is only to check the implementation. The subsequent questions will talk about how exactly you will do the fine-tuning.)

Answer 1:\
One option is to resize the input image to fit into the size of the input by using transforms like resize or crop(which may cause the data to be lost)\
Also many models these days make use of adaptive pooling layer so that before flatterinig the image size does not affect the shapes and just before flattening the output get converted to a fixed size
**Answer 2**:\
This can be done by different ways
one way is to use another layer which convert this 1000 class into 10 class for which we need to learn the weights\
But a commongly employed way in case of transfer learning of these kind of problems is to keep only the initial CNN and Pooling layer and change the final fully connected layer to suit the need of the application that is change the final layer so that the output is only 10 classes and learn these weights with finetuning
"""

weights=torchvision.models.ViT_B_16_Weights.DEFAULT
auto_transforms=weights.transforms()
model=torchvision.models.vit_b_16(weights=weights)

auto_transforms

import torch.nn as nn
model.heads=nn.Sequential(nn.Linear(in_features=768, out_features=10))
model

from torchvision import models
class VIT_iNaturalist(pl.LightningModule):
    def __init__(self,num_classes=10,optimizer=torch.optim.Adam,lr=0.001,weights=models.ViT_B_16_Weights.DEFAULT):
      super().__init__()
      self.optimizer=optimizer
      self.lr=lr
      self.model =models.vit_b_16(weights=weights)
      self.model.heads=nn.Sequential(nn.Linear(in_features=768, out_features=num_classes))
    def forward(self, x):
        return self.model(x)
    def training_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("train_acc", acc, prog_bar=True)
        self.log("train_loss", loss, prog_bar=True)
        return loss
    def validation_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("validation_acc", acc, prog_bar=True)
        self.log("validation_loss", loss, prog_bar=True)
        return {"validation_loss":loss,"validation_acc":acc}
    def test_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("test_acc", acc, prog_bar=True,)
        self.log("test_loss", loss, prog_bar=True)
        return {"test_loss":loss,"test_acc":acc}
    def configure_optimizers(self):
        return self.optimizer(self.model.parameters(), lr=self.lr,weight_decay=1e-5)

class Transfer_iNaturalistModel(pl.LightningModule):
    def __init__(self,num_classes=10,optimizer=torch.optim.Adam,lr=0.001,base=models.resnet50(weights="DEFAULT")):
      super().__init__()
      self.optimizer=optimizer
      self.lr=lr
      num_filters = base.fc.in_features
      layers = list(base.children())[:-1]
      self.feature_extractor = nn.Sequential(*layers)
      self.model = nn.Linear(num_filters, num_classes)
    def forward(self, x):
        x=self.feature_extractor(x)
        x=torch.flatten(x,start_dim=1)
        return self.model(x)
    def training_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("train_acc", acc, prog_bar=True)
        self.log("train_loss", loss, prog_bar=True)
        return loss
    def validation_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("validation_acc", acc, prog_bar=True)
        self.log("validation_loss", loss, prog_bar=True)
        return {"validation_loss":loss,"validation_acc":acc}
    def test_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("test_acc", acc, prog_bar=True)
        self.log("test_loss", loss, prog_bar=True)
        return {"test_loss":loss,"test_acc":acc}
    def configure_optimizers(self):
        return self.optimizer(self.model.parameters(), lr=self.lr,weight_decay=1e-5)











"""## Question 2 (5 Marks)
You will notice that ```GoogLeNet```, ```InceptionV3```, ```ResNet50```, ```VGG```, ```EfficientNetV2```, ```VisionTransformer``` are very huge models as compared to the simple model that you implemented in Part A. Even fine-tuning on a small training data may be very expensive. What is a common trick used to keep the training tractable (you will have to read up a bit on this)? Try different variants of this trick and fine-tune the model using the iNaturalist dataset. For example, '_______'ing all layers except the last layer, '_______'ing upto $k$ layers and  '_______'ing the rest. Read up on pre-training and fine-tuning to understand what exactly these terms mean.

Write down the at least $3$ different strategies that you tried (simple bullet points would be fine).

- Freezing the pretrained feature extraction layer and training only the final classifier layer
- Freeze first k layer of the pretrained model and train remaining layers as well as the final fully connected layer
- Train the whole network without freezing anything

#### Training whole model
"""

from torchvision import models
class VIT_iNaturalist_whole(pl.LightningModule):
    def __init__(self,num_classes=10,optimizer=torch.optim.Adam,lr=0.001,weights=models.ViT_B_16_Weights.DEFAULT):
      super().__init__()
      self.save_hyperparameters()
      self.optimizer=optimizer
      self.lr=lr
      self.model =models.vit_b_16(weights=weights)
      self.model.heads=nn.Sequential(nn.Linear(in_features=768, out_features=num_classes))
    def forward(self, x):
        return self.model(x)
    def training_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("train_acc", acc, prog_bar=True)
        self.log("train_loss", loss, prog_bar=True)
        return loss
    def validation_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("validation_acc", acc, prog_bar=True)
        self.log("validation_loss", loss, prog_bar=True)
        return {"validation_loss":loss,"validation_acc":acc}
    def test_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("test_acc", acc, prog_bar=True,)
        self.log("test_loss", loss, prog_bar=True)
        return {"test_loss":loss,"test_acc":acc}
    def configure_optimizers(self):
        return self.optimizer(self.model.parameters(), lr=self.lr,weight_decay=1e-4)

import wandb
import pytorch_lightning as pl
from pytorch_lightning.loggers import WandbLogger
import torchvision.models as models

wandb_logger = WandbLogger(project="DL_assignment2_B")
wandb.init(project="DL_assignment2_B", reinit=True)
weights = models.ViT_B_16_Weights.DEFAULT
auto_transforms = weights.transforms()
batch_size = 32

model=VIT_iNaturalist_whole(optimizer=torch.optim.Adam,lr=3e-4,weights=weights)
naturalist_DM=iNaturalistDataModule(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',batch_size=batch_size,train_transforms=auto_transforms,test_transforms=auto_transforms)

wandb_logger.experiment.config.update({
    "model_class": model.__class__.__name__
})
trainer = pl.Trainer(max_epochs=10, logger=wandb_logger)

trainer.fit(model, naturalist_DM)

wandb.watch(model, log="all", log_freq=100)

wandb.finish()

"""#### Freezing first k layers"""

from torchvision import models
class VIT_iNaturalist_first_k(pl.LightningModule):
    def __init__(self,num_classes=10, k:int=5,optimizer=torch.optim.Adam,lr=0.001,weights=models.ViT_B_16_Weights.DEFAULT):
      super().__init__()

      self.save_hyperparameters()
      self.optimizer=optimizer
      self.lr=lr
      self.model =models.vit_b_16(weights=weights)
      for param in self.model.parameters():
        param.requires_grad = False
      for param in self.model.encoder.layers[k:].parameters():
        param.requires_grad = True
      self.model.heads=nn.Sequential(nn.Linear(in_features=768, out_features=num_classes))
    def forward(self, x):
        return self.model(x)
    def training_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("train_acc", acc, prog_bar=True)
        self.log("train_loss", loss, prog_bar=True)
        return loss
    def validation_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("validation_acc", acc, prog_bar=True)
        self.log("validation_loss", loss, prog_bar=True)
        return {"validation_loss":loss,"validation_acc":acc}
    def test_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("test_acc", acc, prog_bar=True,)
        self.log("test_loss", loss, prog_bar=True)
        return {"test_loss":loss,"test_acc":acc}
    def configure_optimizers(self):
        return self.optimizer(self.model.parameters(), lr=self.lr,weight_decay=1e-4)

import wandb
import pytorch_lightning as pl
from pytorch_lightning.loggers import WandbLogger
import torchvision.models as models


wandb_logger = WandbLogger(project="DL_assignment2_B")
wandb.init(project="DL_assignment2_B", reinit=True)

weights = models.ViT_B_16_Weights.DEFAULT
auto_transforms = weights.transforms()
batch_size = 64

model=VIT_iNaturalist_first_k(optimizer=torch.optim.Adam,lr=0.001,weights=weights,k=7)
naturalist_DM=iNaturalistDataModule(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',batch_size=batch_size,train_transforms=auto_transforms,test_transforms=auto_transforms)

wandb_logger.experiment.config.update({
    "model_class": model.__class__.__name__
})
trainer = pl.Trainer(max_epochs=10, logger=wandb_logger)

trainer.fit(model, naturalist_DM)

wandb.watch(model, log="all", log_freq=100)

wandb.finish()

import wandb
import pytorch_lightning as pl
from pytorch_lightning.loggers import WandbLogger
import torchvision.models as models


wandb_logger = WandbLogger(project="DL_assignment2_B")
wandb.init(project="DL_assignment2_B", reinit=True)

weights = models.ViT_B_16_Weights.DEFAULT
auto_transforms = weights.transforms()
batch_size = 128

model=VIT_iNaturalist_first_k(optimizer=torch.optim.Adam,lr=0.001,weights=weights,k=3)
naturalist_DM=iNaturalistDataModule(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',batch_size=batch_size,train_transforms=auto_transforms,test_transforms=auto_transforms)

wandb_logger.experiment.config.update({
    "model_class": model.__class__.__name__
})
trainer = pl.Trainer(max_epochs=10, logger=wandb_logger)

trainer.fit(model, naturalist_DM)

wandb.watch(model, log="all", log_freq=100)

wandb.finish()

"""#### Train only the dense layer"""

from torchvision import models
class VIT_iNaturalist_dense_only(pl.LightningModule):
    def __init__(self,num_classes=10,optimizer=torch.optim.Adam,lr=0.001,weights=models.ViT_B_16_Weights.DEFAULT):
      super().__init__()

      self.save_hyperparameters()
      self.optimizer=optimizer
      self.lr=lr
      self.model =models.vit_b_16(weights=weights)
      for param in self.model.parameters():
        param.requires_grad = False
      self.model.heads=nn.Sequential(nn.Linear(in_features=768, out_features=num_classes))
    def forward(self, x):
        return self.model(x)
    def training_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("train_acc", acc, prog_bar=True)
        self.log("train_loss", loss, prog_bar=True)
        return loss
    def validation_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("validation_acc", acc, prog_bar=True)
        self.log("validation_loss", loss, prog_bar=True)
        return {"validation_loss":loss,"validation_acc":acc}
    def test_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("test_acc", acc, prog_bar=True,)
        self.log("test_loss", loss, prog_bar=True)
        return {"test_loss":loss,"test_acc":acc}
    def configure_optimizers(self):
        return self.optimizer(self.model.parameters(), lr=self.lr,weight_decay=1e-4)

import wandb
import pytorch_lightning as pl
from pytorch_lightning.loggers import WandbLogger
import torchvision.models as models

wandb_logger = WandbLogger(project="DL_assignment2_B")
weights = models.ViT_B_16_Weights.DEFAULT
auto_transforms = weights.transforms()
batch_size = 128
wandb.init(project="DL_assignment2_B", reinit=True)
model=VIT_iNaturalist_dense_only(optimizer=torch.optim.Adam,lr=0.001,weights=weights)
naturalist_DM=iNaturalistDataModule(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',batch_size=batch_size,train_transforms=auto_transforms,test_transforms=auto_transforms)

wandb_logger.experiment.config.update({
    "model_class": model.__class__.__name__
})
trainer = pl.Trainer(max_epochs=10, logger=wandb_logger)

trainer.fit(model, naturalist_DM)

wandb.watch(model, log="all", log_freq=100)

wandb.finish()

import wandb
import pytorch_lightning as pl
from pytorch_lightning.loggers import WandbLogger
import torchvision.models as models

wandb_logger = WandbLogger(project="DL_assignment2_B")
weights = models.ViT_B_16_Weights.DEFAULT
auto_transforms = weights.transforms()
batch_size = 256
wandb.init(project="DL_assignment2_B", reinit=True)
model=VIT_iNaturalist_dense_only(optimizer=torch.optim.Adam,lr=0.01,weights=weights)
naturalist_DM=iNaturalistDataModule(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',batch_size=batch_size,train_transforms=auto_transforms,test_transforms=auto_transforms)

wandb_logger.experiment.config.update({
    "model_class": model.__class__.__name__
})
trainer = pl.Trainer(max_epochs=10, logger=wandb_logger)

trainer.fit(model, naturalist_DM)

wandb.watch(model, log="all", log_freq=100)

wandb.finish()

"""## Question 3 (10 Marks)
Now fine-tune the model using **ANY ONE** of the listed strategies that you discussed above. Based on these experiments write down some insightful inferences comparing training from scratch and fine-tuning a large pre-trained model.

- From the graphs it is visible that for almost same parameter just differing the number of layer trained a almost perfect ordering based on the number of layers trained
- As the number of layer that need to be trained decrease the batch size supported in a fixed memory increase also the amount of time required to run the experiment decrease
Training only the final layer
- More faster computations as the amount of computation need to be done is limited to the final layer
- Better performance due to the pretrained layers which are optimized for much larger dataset size
- In training from scratch, due to the number of parametes there are much more precks and vallys which may cause the model to get stuck in but in case of using pretrained model some exploration has been alsready done on these higher dimensional space and like better weight initialization technique it help in reducing the amount of time required to reach or more easily abstract the hidden relation from the  fine tuning data

Choosing to freeze all the encoder block and finetune only the final classifier head of VIT model
"""

weights=torchvision.models.ViT_B_16_Weights.DEFAULT
auto_transforms=weights.transforms()
auto_transforms

from torchvision import transforms
from torchvision.transforms import InterpolationMode
mean=[0.485, 0.456, 0.406]
std=[0.229, 0.224, 0.225]
train_transform = transforms.Compose([
    transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=mean, std=std)
])

class TransformedSubset(torch.utils.data.Dataset):
    def __init__(self, subset, transform):
        self.subset = subset
        self.transform = transform

    def __getitem__(self, index):
        x, y = self.subset[index]
        x = self.transform(x)
        return x, y

    def __len__(self):
        return len(self.subset)

class iNaturalistDataModule_finetune(pl.LightningDataModule):
    def __init__(self, train_dir: str,test_dir: str, batch_size: int=128, num_workers: int = 2,train_transforms=transforms.ToTensor(), test_transforms=transforms.ToTensor(), train_val_split: float = 0.8,seed=3407):
      super().__init__()

      self.save_hyperparameters()
      self.train_dir = train_dir
      self.test_dir = test_dir
      self.batch_size = batch_size
      self.num_workers = num_workers
      self.train_val_split = train_val_split

      self.train_transforms = train_transforms
      self.test_transforms=test_transforms
      self.seed=seed

    def setup(self, stage=None):
      torch.manual_seed(self.seed)
      torch.cuda.manual_seed(self.seed)
      full_dataset = ImageFolder(root=self.train_dir)
      total_size = len(full_dataset)
      train_size = int(total_size * self.train_val_split)
      val_size = total_size - train_size
      train_subset, val_subset = random_split(full_dataset, [train_size, val_size])
      self.train_dataset = TransformedSubset(train_subset, self.train_transforms)
      self.val_dataset = TransformedSubset(val_subset, self.test_transforms)
      self.test_dataset = ImageFolder(root=self.test_dir, transform=self.test_transforms)

    def train_dataloader(self):
      return DataLoader(self.train_dataset,batch_size=self.batch_size,shuffle=True,num_workers=self.num_workers)

    def val_dataloader(self):

      return DataLoader(self.val_dataset,batch_size=self.batch_size,shuffle=False, num_workers=self.num_workers)

    def test_dataloader(self):
      return DataLoader(self.test_dataset,batch_size=self.batch_size,shuffle=False,num_workers=self.num_workers)

from torchvision import models
class VIT_iNaturalist_dense_only(pl.LightningModule):
    def __init__(self,num_classes=10,optimizer=torch.optim.Adam,lr=0.001,weights=models.ViT_B_16_Weights.DEFAULT,dropout=0.5,dene_size=0):
      super().__init__()
      self.save_hyperparameters()
      self.optimizer=optimizer
      self.lr=lr
      self.model =models.vit_b_16(weights=weights)
      for param in self.model.parameters():
        param.requires_grad = False
      if dene_size!=0:
        self.model.heads=nn.Sequential(nn.Linear(in_features=768,out_features=dene_size),nn.SELU(), nn.Dropout(p=dropout), nn.Linear(in_features=dene_size, out_features=num_classes))
      else:
        self.model.heads=nn.Sequential(nn.Dropout(p=dropout), nn.Linear(in_features=768, out_features=num_classes))
    def forward(self, x):
        return self.model(x)
    def training_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("train_acc", acc, prog_bar=True)
        self.log("train_loss", loss, prog_bar=True)
        return loss
    def validation_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("validation_acc", acc, prog_bar=True)
        self.log("validation_loss", loss, prog_bar=True)
        return {"validation_loss":loss,"validation_acc":acc}
    def test_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("test_acc", acc, prog_bar=True,)
        self.log("test_loss", loss, prog_bar=True)
        return {"test_loss":loss,"test_acc":acc}
    def configure_optimizers(self):
        return self.optimizer(self.model.parameters(), lr=self.lr,weight_decay=1e-4)

import wandb
sweep_config = {
    "method": "bayes",
    "metric": {
        "name": "validation_loss",
        "goal": "minimize"
    },
    "parameters": {
        "dropout": {
            "values":[0,0.2,0.3,0.5,0.7]
        },
        "batch_size": {
            "values":[32,64,128,256]
        },"dene_size": {
            "values":[0,512,1024,2046]
        },"lr": {
            "values":[1e-3,5e-4,1e-4]
        }
    }
}
sweep_id = wandb.sweep(sweep_config, project="DL-Addignemt2_B_finetune")

import pytorch_lightning as pl
from pytorch_lightning.callbacks import EarlyStopping
early_stop_cb = EarlyStopping(
    monitor="validation_loss",
    min_delta=0.00,
    patience=10,
    verbose=True,
    mode="min"
)

def fine_tune(config=None):
    with wandb.init(config=config):
        config = wandb.config
        wandb_logger = WandbLogger(project="DL-Addignemt2_B_finetune")
        dropout=config.dropout
        batch_size=config.batch_size
        dene_size=config.dene_size
        lr=config.lr
        model=VIT_iNaturalist_dense_only(lr=lr,dropout=dropout,dene_size=dene_size)
        naturalist_DM=iNaturalistDataModule_finetune(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',batch_size=batch_size,train_transforms=train_transform,test_transforms=auto_transforms)
        trainer = pl.Trainer(logger=wandb_logger, max_epochs=100,callbacks=[early_stop_cb])
        trainer.fit(model, naturalist_DM)

wandb.agent(sweep_id, function=fine_tune, count=1)

from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint
def fine_tune(dropout=0.0,batch_size=32,dene_size=32,lr=1e-3):

    early_stop_cb = EarlyStopping(
        monitor="validation_loss",
        min_delta=0.00,
        patience=10,
        verbose=True,
        mode="min"
    )
    checkpoint_cb = ModelCheckpoint(
    monitor="validation_loss",
    mode="min",
    save_top_k=1,
    verbose=True,
    dirpath="checkpoints/",
    filename="best-model"
    )

    wandb_logger = WandbLogger(project="DL-Addignemt2_B_finetune")
    # dropout=config.dropout
    # batch_size=config.batch_size
    # dene_size=config.dene_size
    # lr=config.lr
    model=VIT_iNaturalist_dense_only(lr=lr,dropout=dropout,dene_size=dene_size)
    naturalist_DM=iNaturalistDataModule_finetune(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',batch_size=batch_size,train_transforms=train_transform,test_transforms=auto_transforms)
    trainer = pl.Trainer(logger=wandb_logger, max_epochs=100,callbacks=[early_stop_cb,checkpoint_cb])
    trainer.fit(model, naturalist_DM)
    best_model = iNaturalistModel.load_from_checkpoint(checkpoint_cb.best_model_path)
    trainer.test(best_model, datamodule=naturalist_DM)
    wandb.finish()

fine_tune(dropout=0.7,batch_size=32,dene_size=512,lr=0.0001)

import torch
import pytorch_lightning as pl
from torchvision import transforms
from torch.utils.data import DataLoader, random_split
from torchvision.datasets import ImageFolder
from torchvision import transforms

class TransformedSubset(torch.utils.data.Dataset):
    """Class which help in applying different tranforms to train and validation set"""
    def __init__(self, subset, transform):
        self.subset = subset
        self.transform = transform

    def __getitem__(self, index):
        x, y = self.subset[index]
        x = self.transform(x)
        return x, y

    def __len__(self):
        return len(self.subset)

class iNaturalistDataModule_finetune(pl.LightningDataModule):
    """Apply same transforms to test and validation set"""
    def __init__(self, train_dir: str,test_dir: str, batch_size: int=128, num_workers: int = 2,train_transforms=transforms.ToTensor(), test_transforms=transforms.ToTensor(), train_val_split: float = 0.8,seed=3407):
      super().__init__()

      self.save_hyperparameters()
      self.train_dir = train_dir
      self.test_dir = test_dir
      self.batch_size = batch_size
      self.num_workers = num_workers
      self.train_val_split = train_val_split

      self.train_transforms = train_transforms
      self.test_transforms=test_transforms
      self.seed=seed

    def setup(self, stage=None):
      torch.manual_seed(self.seed)
      torch.cuda.manual_seed(self.seed)
      full_dataset = ImageFolder(root=self.train_dir)
      total_size = len(full_dataset)
      train_size = int(total_size * self.train_val_split)
      val_size = total_size - train_size
      train_subset, val_subset = random_split(full_dataset, [train_size, val_size])
      self.train_dataset = TransformedSubset(train_subset, self.train_transforms)
      self.val_dataset = TransformedSubset(val_subset, self.test_transforms)
      self.test_dataset = ImageFolder(root=self.test_dir, transform=self.test_transforms)

    def train_dataloader(self):
      return DataLoader(self.train_dataset,batch_size=self.batch_size,shuffle=True,num_workers=self.num_workers)

    def val_dataloader(self):

      return DataLoader(self.val_dataset,batch_size=self.batch_size,shuffle=False, num_workers=self.num_workers)

    def test_dataloader(self):
      return DataLoader(self.test_dataset,batch_size=self.batch_size,shuffle=False,num_workers=self.num_workers)

class ImageFolderWithPaths(ImageFolder):
    def __getitem__(self, index):
        original_tuple = super().__getitem__(index)
        path = self.imgs[index][0]
        return original_tuple + (path,)
class iNaturalistDataModule_with_cls_name(pl.LightningDataModule):
    """Same as of part A return class names also"""
    def __init__(self, train_dir: str,test_dir: str, batch_size: int=128, num_workers: int = 2,train_transforms=transforms.ToTensor(), test_transforms=transforms.ToTensor(), train_val_split: float = 0.8,seed=3407):
      super().__init__()

      self.save_hyperparameters()
      self.train_dir = train_dir
      self.test_dir = test_dir
      self.batch_size = batch_size
      self.num_workers = num_workers
      self.train_val_split = train_val_split

      self.train_transforms = train_transforms
      self.test_transforms=test_transforms
      self.seed=seed

    def setup(self, stage=None):
      torch.manual_seed(self.seed)
      torch.cuda.manual_seed(self.seed)

      train_dataset = ImageFolderWithPaths(root=self.train_dir, transform=self.train_transforms)
      total_size = len(train_dataset)
      train_size = int(total_size * self.train_val_split)
      val_size = total_size - train_size
      self.train_dataset, self.val_dataset = random_split(train_dataset, [train_size, val_size])

      self.test_dataset = ImageFolderWithPaths(root=self.test_dir, transform=self.test_transforms)

    def train_dataloader(self):
      return DataLoader(self.train_dataset,batch_size=self.batch_size,shuffle=True,num_workers=self.num_workers)

    def val_dataloader(self):

      return DataLoader(self.val_dataset,batch_size=self.batch_size,shuffle=False, num_workers=self.num_workers)

    def test_dataloader(self):
      return DataLoader(self.test_dataset,batch_size=self.batch_size,shuffle=False,num_workers=self.num_workers)

import os, random,torch,torchvision
import torch.nn as nn
import torch.functional as F
import torch.optim as optim
import pytorch_lightning as pl
from torchvision import transforms, datasets
from PIL import Image
from torch.utils.data import DataLoader, random_split
from torchvision import models
from pytorch_lightning.loggers import WandbLogger
from torchvision.datasets import ImageFolder
from torch.utils.data import Subset
from torch.nn import init

from torch.optim.lr_scheduler import ReduceLROnPlateau


from torchvision import models
class VIT_iNaturalist_dense_only(pl.LightningModule):

    """Use the Vision transformer as the base model and modify the fully connected layer to suit the needs,
    if the dense size is mentioned as 0 the output of the transformer block will the directly connected to the final output neuron else there will be a fully connected set of neurons in between
    """
    def __init__(self,num_classes=10,optimizer=torch.optim.Adam,lr=0.001,weights=models.ViT_B_16_Weights.DEFAULT,dropout=0.5,dene_size=0,weight_decay=0):
      super().__init__()
      self.save_hyperparameters()
      self.optimizer=optimizer
      self.lr=lr
      self.model =models.vit_b_16(weights=weights)
      self.weight_decay =weight_decay

      for param in self.model.parameters():
        param.requires_grad = False
      if dene_size!=0:
        self.model.heads=nn.Sequential(nn.Linear(in_features=768,out_features=dene_size),nn.SELU(), nn.Dropout(p=dropout), nn.Linear(in_features=dene_size, out_features=num_classes))
      else:
        self.model.heads=nn.Sequential(nn.Dropout(p=dropout), nn.Linear(in_features=768, out_features=num_classes))
    def forward(self, x):
        return self.model(x)
    def training_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("train_acc", acc, prog_bar=True)
        self.log("train_loss", loss, prog_bar=True)
        return loss
    def validation_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("validation_acc", acc, prog_bar=True)
        self.log("validation_loss", loss, prog_bar=True)
        return {"validation_loss":loss,"validation_acc":acc}
    def test_step(self, batch, batch_idx):
        images, labels = batch
        logits = self.forward(images)
        loss = nn.functional.cross_entropy(logits, labels)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == labels).float().mean()
        self.log("test_acc", acc, prog_bar=True,)
        self.log("test_loss", loss, prog_bar=True)
        return {"test_loss":loss,"test_acc":acc}
    def configure_optimizers(self):
        return self.optimizer(self.model.parameters(), lr=self.lr,weight_decay=self.weight_decay)
        # scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5) #do seems to work good but not used for majority of the runs so commented out
        # return {
        #     "optimizer": optimizer,
        #     "lr_scheduler": {
        #         "scheduler": scheduler,
        #         "monitor": "validation_loss",  # name of metric to monitor
        #         "interval": "epoch",
        #         "frequency": 1
        #     }
        # }

import random
import torch,torchvision
import pytorch_lightning as pl
from torchvision import transforms
from torchvision.transforms import InterpolationMode
from torch.optim.lr_scheduler import ReduceLROnPlateau
from pytorch_lightning.callbacks import EarlyStopping
from pytorch_lightning.loggers import WandbLogger
import torch
import wandb

from PIL import Image

def log_random_predictions_separate(
    model,
    dataset,
    class_names,
    device,
    num_samples=30,
    key="random_preds"
):
    """Function which log grid of 30 images to wandb"""
    model.eval().to(device)
    indices = random.sample(range(len(dataset)), num_samples)
    samples = [dataset[i] for i in indices]
    images_to_log = []
    with torch.no_grad():
        for img_tensor, label, path in samples:
            inp = img_tensor.unsqueeze(0).to(device)
            output = model(inp)
            pred = output.argmax(dim=1).item()
            img = Image.open(path).convert("RGB")
            caption = f"Pred: {class_names[pred]} / Actual: {class_names[label]}"
            images_to_log.append(wandb.Image(img, caption=caption))
    wandb.log({ key: images_to_log })

from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint
def fine_tune(config=None):
    """Function which was ran as part of wandb runs
    given sweep config it will create and run the model based on the config
    """
    with wandb.init(config=config):
        torch.manual_seed(3407)
        torch.cuda.manual_seed(3407)
        mean=[0.485, 0.456, 0.406]
        std=[0.229, 0.224, 0.225]
        train_transform = transforms.Compose([
            transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),
            transforms.RandomResizedCrop(224),
            transforms.RandomHorizontalFlip(),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std)
        ])
        weights=torchvision.models.ViT_B_16_Weights.DEFAULT
        auto_transforms=weights.transforms()
        early_stop_cb = EarlyStopping(monitor="validation_loss",min_delta=0.00,patience=10,verbose=True,mode="min")
        config = wandb.config
        wandb_logger = WandbLogger(project="DL-Addignemt2_B_finetune")
        dropout=config.dropout
        batch_size=config.batch_size
        dene_size=config.dene_size
        lr=config.lr
        model=VIT_iNaturalist_dense_only(lr=lr,dropout=dropout,dene_size=dene_size)
        naturalist_DM=iNaturalistDataModule_finetune(train_dir='inaturalist_12K/train',test_dir='inaturalist_12K/val',batch_size=batch_size,train_transforms=train_transform,test_transforms=auto_transforms)
        trainer = pl.Trainer(logger=wandb_logger, max_epochs=100,callbacks=[early_stop_cb])
        trainer.fit(model, naturalist_DM)
def fine_tune_manual(project="DL-Addignemt2_B_finetune",dropout=0,batch_size=64,dense_size=0,lr=1e-3,epochs=10):
    """By passing arguments from the cli it create a class which make use of torchviion ViT model and its weights
    For training small modifications to the original transforms defined with the model is applied and for validation and test set the origianal transforms directly used
    Early stopping callback will terminate the training if the validation loss keep on increasing for more than 10 steps
    Checkpoint callback save the best model
    once training is completed the prediciton of test model is made from the model which was having least validation loss
    """
    mean=[0.485, 0.456, 0.406]
    std=[0.229, 0.224, 0.225]
    train_transform = transforms.Compose([
        transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
        transforms.ToTensor(),
        transforms.Normalize(mean=mean, std=std)
    ])
    weights=torchvision.models.ViT_B_16_Weights.DEFAULT
    auto_transforms=weights.transforms()
    wandb.login()
    early_stop_cb = EarlyStopping(monitor="validation_loss",min_delta=0.00,patience=10,verbose=True,mode="min")
    checkpoint_cb = ModelCheckpoint(monitor="validation_loss",mode="min",save_top_k=1,verbose=True,dirpath="checkpoints/",filename="best-model")
    wandb_logger = WandbLogger(project=project)
    model=VIT_iNaturalist_dense_only(lr=lr,dropout=dropout,dene_size=dense_size)
    naturalist_DM=iNaturalistDataModule_finetune(train_dir='src/inaturalist_12K/train',test_dir='src/inaturalist_12K/val',batch_size=batch_size,train_transforms=train_transform,test_transforms=auto_transforms)
    trainer = pl.Trainer(logger=wandb_logger, max_epochs=epochs,callbacks=[early_stop_cb,checkpoint_cb])
    trainer.fit(model, naturalist_DM)
    best_model = VIT_iNaturalist_dense_only.load_from_checkpoint(checkpoint_cb.best_model_path)
    trainer.test(best_model, datamodule=naturalist_DM)
    device='cuda' if torch.cuda.is_available() else 'cpu'
    naturalist_DM_new = iNaturalistDataModule_with_cls_name(
    train_dir='src/inaturalist_12K/train',
    test_dir='src/inaturalist_12K/val',
    batch_size=batch_size,
    train_transforms=train_transform,
    test_transforms=auto_transforms
    )
    naturalist_DM_new.setup()
    class_names = naturalist_DM_new.test_dataset.classes
    log_random_predictions_separate(best_model,naturalist_DM_new.test_dataset,class_names,device=device,num_samples=30,key="Model prediction")
    wandb.finish()

fine_tune_manual(
        project="DL-Addignemt2_B_finetune",
        batch_size=128,
dense_size=2046,
dropout=0.7,
lr=0.0001,
        epochs=17
    )

















"""
## Question 4 (10 Marks)
Paste a link to your GitHub code for Part B

Example: https://github.com/&lt;user-id&gt;/da6401_assignment2/partB

Follow the same instructions as in Question 5 of Part A.
"""









"""# (UNGRADED, OPTIONAL) Part C : Using a pre-trained model as it is

## Question 1 (0 Marks)
Object detection is the task of identifying objects (such as cars, trees, people, animals) in images. Over the past 6 years, there has been tremendous progress in object detection with very fast and accurate models available today. In this question you will use a pre-trained YoloV3 model and use it in an application of your choice. Here is a cool demo of YoloV2 (click on the image to see the demo on youtube).

[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/VOC3huqHrss/0.jpg)](https://www.youtube.com/watch?v=VOC3huqHrss)


Go crazy and think of a cool application in which you can use object detection (alerting lab mates of monkeys loitering outside the lab, detecting cycles in the CRC corridor, ....).

Make a similar demo video of your application, upload it on youtube and paste a link below (similar to the demo I have pasted above).

Also note that I do not expect you to train any model here but just use an existing model as it is. However, if you want to fine-tune the model on some application-specific data then you are free to do that (it is entirely up to you).

Notice that for this question I am not asking you to provide a GitHub link to your code. I am giving you a free hand to take existing code and tweak it for your application. Feel free to paste the link of your code here nonetheless (if you want).

Example: https://github.com/&lt;user-id&gt;/da6401_assignment2/partC

## Clitry
"""

!git clone https://key@github.com/sankarvinayak/DL-assignment2.git

import os
os.chdir("DL-assignment2")

!pip install -r requirements.txt

os.chdir('A/')

!python main.py --epoch 1

import os
os.chdir("../B")

!python main.py --epochs 1

